{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e877fc51",
   "metadata": {},
   "source": [
    "# Головина Анна Анатольевна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "66948d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import collections\n",
    "from fake_useragent import UserAgent\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import random\n",
    "import requests\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb67d52",
   "metadata": {},
   "source": [
    "1. Сначала нам надо скачать данные -- соберите как минимум 60 (30 положительных и 30 отрицательных) отзывов на похожие продукты для составления \"тонального словаря\" и 10 отзывов для проверки качества."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcd0452",
   "metadata": {},
   "source": [
    "Несмотря на все меры предосторожности, меня заблокировало 5 сайтов, поэтому код доступа оставила просто как достижение и в каждом цикле, связанном с краулером, использовала рандомные паузы в диапазоне от 5 до 20 секунд.\n",
    "\n",
    "Выбрала сайт [\"Право голоса\"](https://pravogolosa.net), где можно отфильтровать страну и город отзыва, выбрать положительные, негативные или нейтральные отзывы (удобно для сохранения баланса при сборе данных) и настроить категорию товаров или услуг. И в целом это позволит изначально разделить тренировочные отзывы на положительные и отрицательные.\n",
    "\n",
    "Оценивала тональность отзывов на IT-услуги в Москве, взяла 90 положительных и 90 отрицательных отзывов (от каждого потом отсекла по 5 для проверки качества)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "43f390c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = requests.session()\n",
    "response = session.get(\"https://pravogolosa.net\")\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cb2033",
   "metadata": {},
   "source": [
    "Я пыталась написать функцию, которая позволит одинаково вытащить тексты отзывов как по фильтру \"положительный\", так и \"негативный\" без необходимости дублировать код. Но из-за размещения положительных и отрицательных отзывов на разных страницах, наличия форматированной строки в цикле (для перебора страниц), а также зацикленной дозаписи в список ссылок этого не вышло, вынесла в функции тот максимум, который смогла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "57876438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_extractor(link):\n",
    "    \"\"\"\n",
    "    Общая функция для получения html страницы\n",
    "    Аргумент - ссылка на страницу\n",
    "    Вывод - html исходной страницы\n",
    "    \"\"\"\n",
    "    user_agent = UserAgent().chrome\n",
    "    response = requests.get(link, headers={'User-Agent':user_agent})\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "516aa783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def previews_extractor(block_url):\n",
    "    \"\"\"\n",
    "    Функция для получения html превью индивидуальных отзывов для одного блока\n",
    "    Использует общую функцию парсинга\n",
    "    Аргумент - ссылка на блок отзывов\n",
    "    Вывод - список превью по одному блоку\n",
    "    \"\"\"\n",
    "    block_soup = html_extractor(block_url)\n",
    "    block_of_previews = block_soup.find_all(\n",
    "        class_=\"ads_text_main\"\n",
    "    )  # превью отзывов по блоку (блок = 20 отзывов, дальше перелистывание)\n",
    "    return block_of_previews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9efd2bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_text_extractor(review_url):\n",
    "    \"\"\"\n",
    "    Функция для получения текста отзыва\n",
    "    Использует общую функцию парсинга\n",
    "    Аргумент - ссылка на отзыв\n",
    "    Вывод - кортеж (заголовок отзыва, текст отзыва)\n",
    "    \"\"\"\n",
    "    review_soup = html_extractor(review_url)\n",
    "\n",
    "    review_text = review_soup.find(\"span\", {\"itemprop\": \"reviewBody\"})\n",
    "    if review_text.find(\"a\"):\n",
    "        review_text.a.decompose()\n",
    "    review_text = review_text.text\n",
    "    return review_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8741929",
   "metadata": {},
   "source": [
    "Сначала соберем ссылки на полные тексты негативных отзывов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "aa70337d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:59<00:00, 11.97s/it]\n"
     ]
    }
   ],
   "source": [
    "neg_hrefs = []\n",
    "for i in tqdm(range(20, 101, 20)):\n",
    "    time.sleep(random.randint(5, 20))\n",
    "    neg_url = f\"https://pravogolosa.net/otzyvcategory?page=show_category&catid=173&order=0&ad_federalstate=%D0%9C%D0%BE%D1%81%D0%BA%D0%B2%D0%B0&ad_country=%D0%A0%D0%BE%D1%81%D1%81%D0%B8%D1%8F&ad_tipre=%D0%9D%D0%B5%D0%B3%D0%B0%D1%82%D0%B8%D0%B2%D0%BD%D1%8B%D0%B9&start={i}\"\n",
    "    neg_previews = previews_extractor(neg_url)\n",
    "\n",
    "    neg_hrefs += [\n",
    "        f\"https://pravogolosa.net{preview.find('h2').find('a').get('href')}\"\n",
    "        for preview in neg_previews\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada3483c",
   "metadata": {},
   "source": [
    "После получения списка ссылок на негативные отзывы обработаем тексты и запишем их в список."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2c7af0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [20:41<00:00, 13.79s/it]\n"
     ]
    }
   ],
   "source": [
    "neg_texts = []\n",
    "\n",
    "for href in tqdm(neg_hrefs):\n",
    "    time.sleep(random.randint(5, 20))\n",
    "    try:\n",
    "        text = review_text_extractor(href)\n",
    "        neg_texts.append(text)\n",
    "    except:\n",
    "        pass # пусть будет заглушка чтобы не генерить лишние файлы при запуске и не перегружать принтами"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07a0e9a",
   "metadata": {},
   "source": [
    "Теперь то же самое проделаем для положительных отзывов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0b87f1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:57<00:00, 11.56s/it]\n"
     ]
    }
   ],
   "source": [
    "pos_hrefs = []\n",
    "for i in tqdm(range(20, 101, 20)):\n",
    "    time.sleep(random.randint(5, 20))\n",
    "    pos_url = f\"https://pravogolosa.net/otzyvcategory?page=show_category&catid=173&order=0&ad_federalstate=%D0%9C%D0%BE%D1%81%D0%BA%D0%B2%D0%B0&ad_country=%D0%A0%D0%BE%D1%81%D1%81%D0%B8%D1%8F&ad_tipre=%D0%9F%D0%BE%D0%BB%D0%BE%D0%B6%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9&start={i}\"\n",
    "    pos_previews = previews_extractor(url)\n",
    "\n",
    "    pos_hrefs += [\n",
    "        f\"https://pravogolosa.net{preview.find('h2').find('a').get('href')}\"\n",
    "        for preview in pos_previews\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "5e6df779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [23:10<00:00, 13.90s/it]\n"
     ]
    }
   ],
   "source": [
    "pos_texts = []\n",
    "\n",
    "for href in tqdm(pos_hrefs):\n",
    "    time.sleep(random.randint(5, 20))\n",
    "    try:\n",
    "        text = review_text_extractor(href)\n",
    "        pos_texts.append(text)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e65705",
   "metadata": {},
   "source": [
    "Положительных отзывов заведомо больше, чем отрицательных, так что проверю размерность списка. Надеюсь, это не считается лишним принтом, я пыталась обосновать код, который мог бы возникнуть, если бы пришлось сокращать список положительных отзывов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5e19287b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "print(len(pos_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbec1c9",
   "metadata": {},
   "source": [
    "2. Токенизируйте слова, приведите их к нижнему регистру и к начальной форме."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9a0e13",
   "metadata": {},
   "source": [
    "Для задачи, во-первых, подключим анализатор, а во-вторых, укажем стоп-слова, которые точно будут информационным мусором для тонального словаря."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "595c2abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()\n",
    "stop_words = set(\n",
    "    stopwords.words(\"russian\")\n",
    ")  # депрессия, в списке есть некоторые предлоги"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5725093",
   "metadata": {},
   "source": [
    "Сделала функцию, в которой происходят и перевод в нижний регистр, и токенизация, и лемматизация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "2095c0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    \"\"\"\n",
    "    Функция для получения лемм слов\n",
    "    Аргумент - строка с текстом отзыва\n",
    "    Вывод - список лемм\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    tokenizer = RegexpTokenizer(r\"[а-я0-9ё]+\")\n",
    "    text_tokenized = tokenizer.tokenize(text)\n",
    "    lemmas = [\n",
    "        morph.parse(word)[0].normal_form\n",
    "        for word in text_tokenized\n",
    "        if (word.isalpha() == True and word not in stop_words)\n",
    "    ]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465af385",
   "metadata": {},
   "source": [
    "Поскольку для составления словаря нужно 60+ отзывов, возьмем по 85 положительных и отрицательных (оставшиеся, как и написано в условии, пойдут на тестирование, их лемматизирую позже, в рамках другой функции)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "2d7525d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_lemmas, pos_lemmas = [], []\n",
    "\n",
    "for i in range(85): # обработаю по 85 первых положительных и отрицательных отзывов\n",
    "    neg_lemmas += lemmatization(neg_texts[i])\n",
    "    pos_lemmas += lemmatization(pos_texts[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc395351",
   "metadata": {},
   "source": [
    "3. Составьте 2 множества - в одном будут слова, которые встречаются только в положительных отзывах, а в другом - встречающиеся только в отрицательных. Попробуйте поиграть с частотностями и исключить шум."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2c88cb",
   "metadata": {},
   "source": [
    "Для поиска характерных для той или иной тональности слов составила функцию, которая сначала создает частотный словарь с фильтром, а затем собирает ключи словаря."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "017cd72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keywords(list_of_lemmas):\n",
    "    \"\"\"\n",
    "    Функция для получения наиболее частотных слов текста\n",
    "    Аргумент - список лемм\n",
    "    Вывод - список отфильтрованных по частотности лемм\n",
    "    \"\"\"\n",
    "    c = collections.Counter()\n",
    "\n",
    "    for lemma in list_of_lemmas:\n",
    "        c[lemma] += 1\n",
    "    # начиная с 6 (т.е. > 5) сильно проседают явно оценочные слова в положительных отзывах\n",
    "    c_filtered = {i: c[i] for i in c.keys() if c[i] > 4}\n",
    "    return list(c_filtered.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb2202b",
   "metadata": {},
   "source": [
    "Создаем temporary sets на основе результатов работы функции со списками лемм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "53d1a24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_temp_set = set(keywords(neg_lemmas))\n",
    "pos_temp_set = set(keywords(pos_lemmas))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c63f2d",
   "metadata": {},
   "source": [
    "Чтобы получить наиболее точные результаты, выкидываем пересечение множеств (где скорее всего окажутся слова, связанные с IT-сферой как общим местом двух типов отзывов, случайно повторяющиеся слова и слова, имеющие двоякое значение в зависимости от контекста)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ad4d44be",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_set = neg_temp_set.difference(pos_temp_set)\n",
    "pos_set = pos_temp_set.difference(neg_temp_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16741fe7",
   "metadata": {},
   "source": [
    "4. Создайте функцию, которая будет определять, положительный ли отзыв или отрицательный в зависимости от того, какие слова встретились в нём, и посчитайте качество при помощи accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aa764f",
   "metadata": {},
   "source": [
    "Если честно, сама не смогла придумать ничего лучше чем это, но эта функция отвратительная и слишком примитивная, поэтому в итоге взяла семинарскую функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "453b2dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_review_rating(review):\n",
    "    \"\"\"\n",
    "    Функция для оценки тональности текста\n",
    "    Аргумент - текст отзыва\n",
    "    Вывод - оценка (1 = положительный, 0 = отрицательный, -1 = непонятно)\n",
    "    \"\"\"\n",
    "    review_lemmas = lemmatization(review)\n",
    "    neg_counter, pos_counter = 0, 0\n",
    "    for lemma in review_lemmas:\n",
    "        if lemma in pos_set:\n",
    "            pos_counter += 1\n",
    "        elif lemma in neg_set:\n",
    "            neg_counter += 1\n",
    "    if pos_counter > neg_counter:\n",
    "        return 1\n",
    "    elif pos_counter < neg_counter:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab913009",
   "metadata": {},
   "source": [
    "Вот модифицированная под задачу семинарская."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "90020312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_rating(ratings, review):\n",
    "    \"\"\"\n",
    "    Функция для оценки тональности текста\n",
    "    Аргумент - текст отзыва\n",
    "    Вывод - оценка\n",
    "    \"\"\"\n",
    "    review_lemmas = lemmatization(review)\n",
    "\n",
    "    rev_rating = collections.Counter()\n",
    "    for grade, word_set in ratings.items():\n",
    "        word_set = collections.Counter(word_set)\n",
    "        for lemma in review_lemmas:\n",
    "            rev_rating[grade] += int(word_set[lemma] > 0)\n",
    "    return rev_rating.most_common()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca2f573",
   "metadata": {},
   "source": [
    "Создам словарь с двумя ключами-оценками, где 0 - отрицательная, а 1 - положительная оценка. Значениями в данном случае будут выступать множества (и в предыдущем задании, и здесь работаю с множествами во имя скорости обработки)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "47266534",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_dict = {0: neg_set, 1: pos_set}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f272238",
   "metadata": {},
   "source": [
    "Реальная тональность отзывов мне заведомо известна благодаря выбранному сайту, и поскольку в список *test_data* отзывы добавлены вручную склейкой \"хвостов\" изначальных списков с отзывами, их корректную оценку также можно вручную записать через склейку списков нулей и единиц."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "1d9a8a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pos_texts[85:] + neg_texts[85:]\n",
    "\n",
    "correct = [1 for i in range(len(pos_texts[85:]))] + [\n",
    "    0 for i in range(len(neg_texts[85:]))\n",
    "]\n",
    "predicted = [review_rating(ratings_dict, item) for item in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "cc3e40aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(correct, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96568f8",
   "metadata": {},
   "source": [
    "В целом, не самый плохой результат для выбранного подхода.\n",
    "\n",
    "UPD: не очень понимаю, в чем дело, изначально я собирала 91 положительный отзыв и отсекала последний, точность была равна 0.7, на следующий день запустила код заново, собралось ровно 90 положительных отзывов, точность сначала взлетела до 1 (а я не очень верю, что подобный алгоритм действительно так хорошо предсказывает), затем я увеличила фильтр по частотности c (> 3) до (> 4), точность стала 0.8. Видимо, положительные отзывы дополнялись, поэтому первоначальные данные поехали."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fcef04",
   "metadata": {},
   "source": [
    "**Итог**: реализация немного примитивная (старалась по максимуму отойти от семинарских материалов), но работает, на том спасибо."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f34270",
   "metadata": {},
   "source": [
    "5. Предложите как минимум 2 способа улучшить этот алгоритм определения тональности отзыва (1 балл за описание и реализацию каждого способа; если 2 способа описаны только текстом, это 1 балл. За третий и последующие способы дополнительных баллов не будет)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47216173",
   "metadata": {},
   "source": [
    "Все способы, какие смогла придумать, вдохновлены ридингом, то есть все решения про векторные представления слов.\n",
    "\n",
    "**1 способ**: можно решить через bag-of-words (то есть нужно будет собрать все леммы всех отзывов в общий вектор и относительно словаря преобразовывать каждый отзыв в частотный вектор). Признаки (положительность/отрицательность тона) будут извлекаться из текста уже на основе частотности тех или иных слов в тексте каждого отзыва. В таком случае можно будет создать какую-нибудь модель (на основе логистической регрессии, k ближайших соседей или случайного леса) и обучить ее на классификацию по тональности.\n",
    "\n",
    "**2 способ**: с помощью генерации эмбеддингов (то есть через word2vec). В таком случае в качестве инпута даем все тексты отзывов и получаем слова, преобразованные в вектора не на основе частотности, а на основе семантической близости (тогда слова с яркой оценочностью будут ближе друг к другу). Далее уже последует обучение модели, о котором сказано в предыдущем способе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53938e24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
